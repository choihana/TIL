{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/euphoris/datasets/raw/master/imdb.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3         Very little music or anything to speak of.          0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 문서 행렬 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features= 1000, stop_words='english')\n",
    "tdm = cv.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터분할 (train, test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tdm #단어 컬럼\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size = 0.2, random_state = 1111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1000) (800,)\n",
      "(200, 1000) (200,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀분석 with 텐서플로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-macosx_10_14_x86_64.whl (165.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 165.2 MB 7.0 MB/s eta 0:00:01   |█                               | 5.6 MB 4.1 MB/s eta 0:00:40     |███                             | 15.2 MB 4.9 MB/s eta 0:00:31     |█████▎                          | 27.0 MB 3.3 MB/s eta 0:00:42     |█████████                       | 46.0 MB 4.9 MB/s eta 0:00:25     |██████████▍                     | 53.4 MB 10.5 MB/s eta 0:00:11     |████████████▉                   | 66.4 MB 2.4 MB/s eta 0:00:42     |██████████████▍                 | 74.5 MB 1.8 MB/s eta 0:00:51     |███████████████▏                | 78.0 MB 1.8 MB/s eta 0:00:49     |████████████████████▏           | 103.9 MB 3.5 MB/s eta 0:00:18     |████████████████████████▉       | 128.3 MB 3.1 MB/s eta 0:00:12\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.33.2-cp38-cp38-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=12cb59e18e7dc1501283a6b7273c93463aef0b13b8e94796fbad80879e1fd740\n",
      "  Stored in directory: /Users/hana/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: opt-einsum, keras-preprocessing, tensorboard-plugin-wit, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, google-auth-oauthlib, protobuf, grpcio, markdown, absl-py, tensorboard, gast, tensorflow-estimator, astunparse, google-pasta, termcolor, tensorflow\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 keras-preprocessing-1.1.2 markdown-3.3.3 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    1,  # 출력은 긍정(1)/부정(0) 하나\n",
    "    input_shape=(1000,), # 입력은 단어 수\n",
    "    activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 1,001\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.8700\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.8775\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.8825\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.8888\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.8875\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.8950\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.8988\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.9013\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.9038\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.9050\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.9062\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.9075\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.9087\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.9087\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.9112\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.9125\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.9137\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.9150\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.9150\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.9162\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.9175\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9175\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.9200\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.9187\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.9225\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.9225\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.9212\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.9250\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.9250\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.9237\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.9250\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.9262\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.9275\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.9287\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.9287\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.9287\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.9287\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.9287\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.9275\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.9275\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.9287\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.9287\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.9300\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.9312\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.9325\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.9325\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.9337\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.9337\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b56ae20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train.values, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 924us/step - loss: 0.4994 - accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4993995428085327, 0.7950000166893005]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: imdb-sentiment.krs/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('imdb-sentiment.krs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어별 가중치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weight = pd.DataFrame({\n",
    "    '단어':cv.get_feature_names(),\n",
    "    '가중치': weight.numpy().flat\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.884455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.774360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.703701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>stupid</td>\n",
       "      <td>-0.696910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>script</td>\n",
       "      <td>-0.615045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>cheap</td>\n",
       "      <td>-0.593982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>plot</td>\n",
       "      <td>-0.591006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>wasted</td>\n",
       "      <td>-0.585696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>started</td>\n",
       "      <td>-0.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>holes</td>\n",
       "      <td>-0.578451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>trash</td>\n",
       "      <td>-0.556141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>worse</td>\n",
       "      <td>-0.551958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.549090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>costs</td>\n",
       "      <td>-0.539747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>half</td>\n",
       "      <td>-0.536942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>annoying</td>\n",
       "      <td>-0.527698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.524316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>hours</td>\n",
       "      <td>-0.522775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>didn</td>\n",
       "      <td>-0.522704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>torture</td>\n",
       "      <td>-0.517224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           단어       가중치\n",
       "69        bad -0.884455\n",
       "68      awful -0.774360\n",
       "986     worst -0.703701\n",
       "842    stupid -0.696910\n",
       "763    script -0.615045\n",
       "134     cheap -0.593982\n",
       "658      plot -0.591006\n",
       "950    wasted -0.585696\n",
       "827   started -0.582100\n",
       "413     holes -0.578451\n",
       "898     trash -0.556141\n",
       "985     worse -0.551958\n",
       "419  horrible -0.549090\n",
       "179     costs -0.539747\n",
       "389      half -0.536942\n",
       "45   annoying -0.527698\n",
       "65      avoid -0.524316\n",
       "422     hours -0.522775\n",
       "224      didn -0.522704\n",
       "895   torture -0.517224"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정적인 단어\n",
    "word_weight.sort_values('가중치').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>love</td>\n",
       "      <td>0.713425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>liked</td>\n",
       "      <td>0.694925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>great</td>\n",
       "      <td>0.694204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.650863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.649958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.636237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.622293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>0.594056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hilarious</td>\n",
       "      <td>0.580077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>interesting</td>\n",
       "      <td>0.569849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>think</td>\n",
       "      <td>0.569709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>portrayal</td>\n",
       "      <td>0.557857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>performance</td>\n",
       "      <td>0.550962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>job</td>\n",
       "      <td>0.547024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>0.546996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>years</td>\n",
       "      <td>0.542872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>subtle</td>\n",
       "      <td>0.537567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>played</td>\n",
       "      <td>0.535586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>makes</td>\n",
       "      <td>0.514788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>fun</td>\n",
       "      <td>0.511447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              단어       가중치\n",
       "529         love  0.713425\n",
       "503        liked  0.694925\n",
       "382        great  0.694204\n",
       "594         nice  0.650863\n",
       "530        loved  0.649958\n",
       "976    wonderful  0.636237\n",
       "292    excellent  0.622293\n",
       "76     beautiful  0.594056\n",
       "409    hilarious  0.580077\n",
       "449  interesting  0.569849\n",
       "881        think  0.569709\n",
       "667    portrayal  0.557857\n",
       "636  performance  0.550962\n",
       "460          job  0.547024\n",
       "279      enjoyed  0.546996\n",
       "996        years  0.542872\n",
       "846       subtle  0.537567\n",
       "651       played  0.535586\n",
       "539        makes  0.514788\n",
       "353          fun  0.511447"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정적인 단어\n",
    "word_weight.sort_values('가중치',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
